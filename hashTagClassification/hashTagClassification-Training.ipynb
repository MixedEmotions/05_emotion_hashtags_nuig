{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier on HashTag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported regex as re\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk.tokenize.casual as casual\n",
    "from drevicko.twitter_regexes import cleanString, setupRegexes, tweetPreprocessor\n",
    "import preprocess_twitter\n",
    "\n",
    "def preprocess_tweet(text):\n",
    "    \n",
    "    text = casual.reduce_lengthening(text)\n",
    "    text = cleanString(setupRegexes('twitterProAna'),text)   \n",
    "    text = ' '.join([span for notentity,span in tweetPreprocessor(text, (\"urls\", \"users\", \"lists\")) if notentity])\n",
    "    text = text.replace('\\t','')\n",
    "    text = text.replace('< ','<')\n",
    "    text = text.replace(' >','>')\n",
    "    text = text.replace('):', '<sadface>')\n",
    "    text = text.replace('(:', '<smile>')\n",
    "    return text\n",
    "\n",
    "def tokenise_tweet(text):\n",
    "    text = preprocess_twitter.tokenize(text)\n",
    "    text = preprocess_tweet(text)     \n",
    "    return ' '.join(text.split())\n",
    "\n",
    "emoNames = ['sadness', 'disgust', 'surprise', 'anger', 'fear', 'joy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run( ['wget', 'http://saifmohammad.com/WebDocs/Jan9-2012-tweets-clean.txt.zip'], stdout=subprocess.PIPE )\n",
    "subprocess.run( ['unzip', 'Jan9-2012-tweets-clean.txt.zip'], stdout=subprocess.PIPE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def _load_data(filename = \"Jan9-2012-tweets-clean.txt\", preprocess=True):\n",
    "\n",
    "    lines, tweets_id, tweets_text = [],[],[]\n",
    "\n",
    "    for line in open(filename, 'rb'):\n",
    "\n",
    "        line = line.decode(\"utf-8\")\n",
    "        tw_id = line[0:17]\n",
    "        tweets_id.append(tw_id)    \n",
    "        tw_text, tw_emo = line[19:].split(\"\\t:: \")\n",
    "        \n",
    "        if(preprocess):\n",
    "            tw_text = tokenise_tweet(tw_text)\n",
    "        \n",
    "        lines.append((tw_text,tw_emo.strip()))\n",
    "        tweets_text.append(tw_text)\n",
    "\n",
    "    tweets_set = defaultdict(lambda : {'tweet':'', 'sadness': 0,  'disgust': 0,'surprise': 0,'anger': 0,'fear': 0,'joy': 0})\n",
    "\n",
    "    for i,t in zip(tweets_id,lines):\n",
    "        tw, emo = t    \n",
    "        tweets_set[i]['tweet'] = tw\n",
    "        tweets_set[i][emo] = 1\n",
    "\n",
    "    tweets,labels = [],[]\n",
    "\n",
    "    for i in tweets_set:\n",
    "        tweets.append(tweets_set[i]['tweet'])\n",
    "        labels.append([tweets_set[i][e] for e in emoNames])\n",
    "    \n",
    "    return(tweets,labels)\n",
    "\n",
    "\n",
    "tweets, labels = _load_data(filename = \"Jan9-2012-tweets-clean.txt\", preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD FREQUENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7531 27160\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAFnCAYAAADg7eCkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7554232cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from stop_words import get_stop_words\n",
    "WORD_FREQUENCY_TRESHOLD = 3\n",
    "\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "def ifExists(filename):\n",
    "    dir = os.path.dirname(filename)\n",
    "    try:\n",
    "        os.stat(dir)\n",
    "    except:\n",
    "        os.mkdir(dir) \n",
    "        \n",
    "def checkFolder(filename):\n",
    "    dir = os.path.dirname(filename)\n",
    "    try:\n",
    "        os.stat(dir)\n",
    "    except:\n",
    "        os.mkdir(dir) \n",
    "\n",
    "def _get_unique_tokens(tweets):    \n",
    "    return(Counter(token for tweet in tweets for token in tweet.split()))\n",
    "\n",
    "def _save_unique_tokens(tokens, filename='uniqueTokens.dump'):\n",
    "    \n",
    "    checkFolder(filename)\n",
    "    _ = joblib.dump(tokens, filename=filename, compress=9)\n",
    "    \n",
    "\n",
    "def _plot_word_frequiencies(uniqueTokens, WORD_FREQUENCY_TRESHOLD = 3):\n",
    "    \n",
    "    freqs = []\n",
    "    for t,c in uniqueTokens.items():\n",
    "        freqs.append(c)\n",
    "        \n",
    "    q = 0\n",
    "    for t,c in uniqueTokens.items():\n",
    "        if(c >= WORD_FREQUENCY_TRESHOLD):\n",
    "            q+=1\n",
    "    print(q, len(uniqueTokens))\n",
    "    %pylab inline\n",
    "    semilogy(arange(len(freqs)),sorted(freqs))\n",
    "    show()\n",
    "    \n",
    "\n",
    "def _reduce_text(text, LANGUAGE='en', WORD_FREQUENCY_TRESHOLD = 3):    \n",
    "\n",
    "    stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    tweets_reduced = []\n",
    "\n",
    "    for tw in tweets:\n",
    "        tweet_r = []\n",
    "        for token in tw.split():\n",
    "            if(uniqueTokens[token] >= WORD_FREQUENCY_TRESHOLD):\n",
    "                if(not token in stop_words):\n",
    "                    tweet_r.append(token)\n",
    "\n",
    "        tweets_reduced.append( ' '.join(tweet_r)  )\n",
    "        \n",
    "    return(tweets_reduced)\n",
    "\n",
    "uniqueTokens = _get_unique_tokens(tweets)\n",
    "# _save_unique_tokens(tokens=uniqueTokens,filename = '/home/vlaand/IpythonNotebooks/cf-5point-data/uniqueTokens.dump')\n",
    "\n",
    "_save_unique_tokens(tokens=uniqueTokens,filename = '/home/vlaand/IpythonNotebooks/05_emotion_hashtags_nuig/hashTagClassification/wordFrequencies.dump')\n",
    "_plot_word_frequiencies(uniqueTokens, WORD_FREQUENCY_TRESHOLD = WORD_FREQUENCY_TRESHOLD)\n",
    "tweets_reduced = _reduce_text(tweets, WORD_FREQUENCY_TRESHOLD = WORD_FREQUENCY_TRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7411 7411\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFnCAYAAAD60QAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7554011f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_plot_word_frequiencies(_get_unique_tokens(tweets_reduced), WORD_FREQUENCY_TRESHOLD = WORD_FREQUENCY_TRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21760 tokens in we\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_DIM = 100\n",
    "\n",
    "def _load_original_vectors(filename = 'wordvectors-glove.twitter.27B.200d.txt', sep = ' ', uniqueTokens = None):\n",
    "\n",
    "    Dictionary = {}\n",
    "    \n",
    "    for line in open(filename, 'rb'): \n",
    "        line_d = line.decode('utf-8').split(sep)\n",
    "        token = line_d[0]\n",
    "        \n",
    "        token_vector = np.array(line_d[1:], dtype = 'float32')   \n",
    "        if(uniqueTokens):\n",
    "            if(token in uniqueTokens):                \n",
    "                Dictionary[token] = token_vector\n",
    "        else:\n",
    "            Dictionary[token] = token_vector\n",
    "        \n",
    "            \n",
    "    return(Dictionary)\n",
    "\n",
    "# uniqueTokens param is for reading the WE vectors that are present in the text\n",
    "Dictionary = _load_original_vectors(filename = '/home/vlaand/data/Glove/glove.twitter.27B/glove.twitter.27B.'+str(EMBEDDINGS_DIM)+'d.txt', sep = ' ', uniqueTokens=uniqueTokens)\n",
    "print(len(Dictionary),'tokens in we')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGRAM_VALUE = 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "NGRAM_VALUE = 4\n",
    "\n",
    "print('NGRAM_VALUE =',NGRAM_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ngramizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21009 18590\n",
      "/home/vlaand/IpythonNotebooks/hashtag-data/ngramizers/ngramizer.dump saved\n",
      "/home/vlaand/IpythonNotebooks/05_emotion_hashtags_nuig/hashTagClassification/ngramizers/ngramizer.dump saved\n"
     ]
    }
   ],
   "source": [
    "def _save_ngramizer(ngramizer, filename = 'ngramizer.dump'):\n",
    "    checkFolder(filename)\n",
    "    _ = joblib.dump(ngramizer, filename=filename, compress=9)\n",
    "    print(filename+' saved')\n",
    "    \n",
    "vectorizer = CountVectorizer(ngram_range = (1,NGRAM_VALUE),token_pattern=r'\\b\\w+\\b', min_df=WORD_FREQUENCY_TRESHOLD)\n",
    "ngramizer = vectorizer.fit(tweets_reduced)\n",
    "vec = ngramizer.transform(tweets_reduced).toarray()\n",
    "print(len(vec), len(vec[0]))\n",
    "    \n",
    "_save_ngramizer(ngramizer = ngramizer, filename = '/home/vlaand/IpythonNotebooks/hashtag-data/ngramizers/ngramizer.dump')\n",
    "_save_ngramizer(ngramizer = ngramizer, filename = '/home/vlaand/IpythonNotebooks/05_emotion_hashtags_nuig/hashTagClassification/ngramizers/ngramizer.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ngramizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vlaand/IpythonNotebooks/05_emotion_hashtags_nuig/hashTagClassification/ngramizers/ngramizer.dump loaded\n",
      "21009 18590\n"
     ]
    }
   ],
   "source": [
    "def _load_ngramizer(filename = 'ngramizer.dump'):\n",
    "    checkFolder(filename)\n",
    "    ngramizer = joblib.load(filename = filename)\n",
    "    print(filename+' loaded')\n",
    "    return ngramizer\n",
    "\n",
    "ngramizer = _load_ngramizer('/home/vlaand/IpythonNotebooks/05_emotion_hashtags_nuig/hashTagClassification/ngramizers/ngramizer.dump')\n",
    "vec = ngramizer.transform(tweets_reduced).toarray()\n",
    "print(len(vec), len(vec[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21009 18892 21009 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math, itertools\n",
    "from scipy import spatial\n",
    "\n",
    "def _vectors_similarity(v1 , v2):\n",
    "    return( 1 - spatial.distance.cosine(v1,v2) )\n",
    "\n",
    "def capitalRatio(tweet):\n",
    "    \n",
    "        firstCap, allCap = 0, 0\n",
    "        length = len(tweet)\n",
    "        if length==0:\n",
    "            return np.array([0,0])\n",
    "\n",
    "        for i,token in enumerate(tweet.split()):\n",
    "            if( token.istitle() ):\n",
    "                firstCap += 1\n",
    "            elif( token.isupper() ):\n",
    "                allCap += 1\n",
    "        return(np.asarray([firstCap/length,allCap/length]))  \n",
    "        \n",
    "\n",
    "def tweetToWordVectors(dictionary, tweet, fixedLength=False):\n",
    "    output = []    \n",
    "    if(fixedLength):\n",
    "        for i in range(MAX_SEQUENCE_LENGTH):\n",
    "            output.append(blankVector)\n",
    "        for i,token in enumerate(tweet.split()):\n",
    "            if token in Dictionary:\n",
    "                output[i] = Dictionary[token]                \n",
    "    else:\n",
    "         for i,token in enumerate(tweet.lower().split()):\n",
    "            if token in Dictionary:\n",
    "                output.append(Dictionary[token])            \n",
    "    return(output)\n",
    "\n",
    "def ModWordVectors(x, mod=True):\n",
    "    if(len(x) == 0):       \n",
    "        if(mod):\n",
    "            return(np.zeros(EMBEDDINGS_DIM*3, dtype='float32'))\n",
    "        else:\n",
    "            return(np.zeros(EMBEDDINGS_DIM, dtype='float32'))        \n",
    "    m =  np.matrix(x)\n",
    "    if(mod):\n",
    "        xMean = np.array(m.mean(0))[0]\n",
    "        xMin = np.array(m.min(0))[0]\n",
    "        xMax = np.array(m.max(0))[0]\n",
    "        xX = np.concatenate((xMean,xMin,xMax))\n",
    "        return(xX)\n",
    "    else:\n",
    "        return(np.array(m.mean(0))[0])\n",
    "\n",
    "def bindTwoVectors(x0,x1):\n",
    "    xX = np.array(list(itertools.chain(x0,x1)),dtype='float32')\n",
    "    return(xX)   \n",
    "\n",
    "def _bind_vectors(x):\n",
    "    xX = np.concatenate(x)\n",
    "    return(xX)     \n",
    "\n",
    "def _convert_text_to_vector(tweets, tweet_original,  Dictionary):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, t in enumerate(tweets): \n",
    "        embeddingsVector = ModWordVectors(tweetToWordVectors(Dictionary,tweets[i]))\n",
    "        capitalRatioVector = capitalRatio(tweet_original[i])\n",
    "        ngramVector = vec[i]\n",
    "        X.append( _bind_vectors((ngramVector, capitalRatioVector, embeddingsVector))  )\n",
    "        y.append(labels[i])\n",
    "    \n",
    "    return(np.asarray(X), y)\n",
    "\n",
    "\n",
    "X,y = _convert_text_to_vector(tweets = tweets_reduced, tweet_original = tweets, Dictionary = Dictionary)\n",
    "  \n",
    "print(len(X), len(X[0]), len(y), len(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: C=0.001, tol=1e-06, score=0.139903381643\n",
      "surprise: C=0.001, tol=1e-06, score=0.32\n",
      "fear: C=0.001, tol=1e-06, score=0.139903381643\n",
      "disgust: C=0.001, tol=1e-06, score=0.0\n",
      "joy: C=0.001, tol=1e-06, score=0.0\n",
      "sadness: C=0.001, tol=1e-06, score=0.125490196078\n",
      "anger: C=0.01, tol=1e-06, score=0.0\n",
      "surprise: C=0.01, tol=1e-06, score=0.0\n",
      "disgust: C=0.01, tol=1e-06, score=0.0\n",
      "fear: C=0.01, tol=1e-06, score=0.0\n",
      "sadness: C=0.01, tol=1e-06, score=0.0\n",
      "joy: C=0.01, tol=1e-06, score=0.0\n",
      "anger: C=0.1, tol=1e-06, score=0.139903381643\n",
      "surprise: C=0.1, tol=1e-06, score=0.216752136752\n",
      "disgust: C=0.1, tol=1e-06, score=0.0563636363636\n",
      "sadness: C=0.1, tol=1e-06, score=0.0\n",
      "fear: C=0.1, tol=1e-06, score=0.139903381643\n",
      "joy: C=0.1, tol=1e-06, score=0.0\n",
      "anger: C=1.0, tol=1e-06, score=0.148666666667\n",
      "surprise: C=1.0, tol=1e-06, score=0.133333333333\n",
      "disgust: C=1.0, tol=1e-06, score=0.0210526315789\n",
      "sadness: C=1.0, tol=1e-06, score=0.0\n",
      "joy: C=1.0, tol=1e-06, score=0.11826625387\n",
      "fear: C=1.0, tol=1e-06, score=0.447619047619\n",
      "anger: C=0.001, tol=1e-05, score=0.139903381643\n",
      "surprise: C=0.001, tol=1e-05, score=0.32\n",
      "disgust: C=0.001, tol=1e-05, score=0.0\n",
      "sadness: C=0.001, tol=1e-05, score=0.125490196078\n",
      "anger: C=0.01, tol=1e-05, score=0.0\n",
      "fear: C=0.001, tol=1e-05, score=0.139903381643\n",
      "joy: C=0.001, tol=1e-05, score=0.0\n",
      "disgust: C=0.01, tol=1e-05, score=0.0\n",
      "surprise: C=0.01, tol=1e-05, score=0.0\n",
      "sadness: C=0.01, tol=1e-05, score=0.0\n",
      "anger: C=0.1, tol=1e-05, score=0.139903381643\n",
      "fear: C=0.01, tol=1e-05, score=0.0\n",
      "joy: C=0.01, tol=1e-05, score=0.0\n",
      "disgust: C=0.1, tol=1e-05, score=0.0563636363636\n",
      "surprise: C=0.1, tol=1e-05, score=0.216752136752\n",
      "anger: C=1.0, tol=1e-05, score=0.148666666667\n",
      "sadness: C=0.1, tol=1e-05, score=0.0\n",
      "fear: C=0.1, tol=1e-05, score=0.139903381643\n",
      "joy: C=0.1, tol=1e-05, score=0.0\n",
      "disgust: C=1.0, tol=1e-05, score=0.0210526315789\n",
      "surprise: C=1.0, tol=1e-05, score=0.133333333333\n",
      "anger: C=0.001, tol=0.0001, score=0.139903381643\n",
      "sadness: C=1.0, tol=1e-05, score=0.0\n",
      "fear: C=1.0, tol=1e-05, score=0.447619047619\n",
      "joy: C=1.0, tol=1e-05, score=0.11826625387\n",
      "anger: C=0.01, tol=0.0001, score=0.0\n",
      "surprise: C=0.001, tol=0.0001, score=0.32\n",
      "disgust: C=0.001, tol=0.0001, score=0.0\n",
      "sadness: C=0.001, tol=0.0001, score=0.125490196078\n",
      "fear: C=0.001, tol=0.0001, score=0.139903381643\n",
      "anger: C=0.1, tol=0.0001, score=0.139903381643\n",
      "joy: C=0.001, tol=0.0001, score=0.0\n",
      "surprise: C=0.01, tol=0.0001, score=0.0\n",
      "disgust: C=0.01, tol=0.0001, score=0.0\n",
      "fear: C=0.01, tol=0.0001, score=0.0\n",
      "sadness: C=0.01, tol=0.0001, score=0.0\n",
      "anger: C=1.0, tol=0.0001, score=0.148666666667\n",
      "joy: C=0.01, tol=0.0001, score=0.0\n",
      "surprise: C=0.1, tol=0.0001, score=0.216752136752\n",
      "disgust: C=0.1, tol=0.0001, score=0.0563636363636\n",
      "anger: C=0.001, tol=1e-06, score=0.139903381643\n",
      "fear: C=0.1, tol=0.0001, score=0.139903381643\n",
      "sadness: C=0.1, tol=0.0001, score=0.0\n",
      "joy: C=0.1, tol=0.0001, score=0.0\n",
      "surprise: C=1.0, tol=0.0001, score=0.133333333333\n",
      "disgust: C=1.0, tol=0.0001, score=0.0210526315789\n",
      "anger: C=0.01, tol=1e-06, score=0.0\n",
      "fear: C=1.0, tol=0.0001, score=0.447619047619\n",
      "sadness: C=1.0, tol=0.0001, score=0.0\n",
      "joy: C=1.0, tol=0.0001, score=0.11826625387\n",
      "surprise: C=0.001, tol=1e-06, score=0.32\n",
      "anger: C=0.1, tol=1e-06, score=0.139903381643\n",
      "disgust: C=0.001, tol=1e-06, score=0.0\n",
      "fear: C=0.001, tol=1e-06, score=0.181570048309\n",
      "sadness: C=0.001, tol=1e-06, score=0.125490196078\n",
      "anger: C=1.0, tol=1e-06, score=0.0666666666667\n",
      "joy: C=0.001, tol=1e-06, score=0.0\n",
      "surprise: C=0.01, tol=1e-06, score=0.0\n",
      "disgust: C=0.01, tol=1e-06, score=0.0\n",
      "fear: C=0.01, tol=1e-06, score=0.0\n",
      "anger: C=0.001, tol=1e-05, score=0.139903381643\n",
      "sadness: C=0.01, tol=1e-06, score=0.0\n",
      "joy: C=0.01, tol=1e-06, score=0.0\n",
      "surprise: C=0.1, tol=1e-06, score=0.154141414141\n",
      "disgust: C=0.1, tol=1e-06, score=0.146666666667\n",
      "fear: C=0.1, tol=1e-06, score=0.302051499717\n",
      "anger: C=0.01, tol=1e-05, score=0.0\n",
      "disgust: C=1.0, tol=1e-06, score=0.0\n",
      "sadness: C=0.1, tol=1e-06, score=0.0\n",
      "surprise: C=1.0, tol=1e-06, score=0.293333333333\n",
      "joy: C=0.1, tol=1e-06, score=0.0\n",
      "fear: C=1.0, tol=1e-06, score=0.394285714286\n",
      "anger: C=0.1, tol=1e-05, score=0.139903381643\n",
      "disgust: C=0.001, tol=1e-05, score=0.0\n",
      "sadness: C=1.0, tol=1e-06, score=0.426153846154\n",
      "anger: C=1.0, tol=1e-05, score=0.0666666666667\n",
      "surprise: C=0.001, tol=1e-05, score=0.32\n",
      "joy: C=1.0, tol=1e-06, score=0.564680756396\n",
      "fear: C=0.001, tol=1e-05, score=0.181570048309\n",
      "disgust: C=0.01, tol=1e-05, score=0.0\n",
      "anger: C=0.001, tol=0.0001, score=0.139903381643\n",
      "sadness: C=0.001, tol=1e-05, score=0.125490196078\n",
      "surprise: C=0.01, tol=1e-05, score=0.0\n",
      "joy: C=0.001, tol=1e-05, score=0.0\n",
      "fear: C=0.01, tol=1e-05, score=0.0\n",
      "anger: C=0.01, tol=0.0001, score=0.0\n",
      "disgust: C=0.1, tol=1e-05, score=0.146666666667\n",
      "sadness: C=0.01, tol=1e-05, score=0.0\n",
      "surprise: C=0.1, tol=1e-05, score=0.154141414141\n",
      "fear: C=0.1, tol=1e-05, score=0.302051499717\n",
      "joy: C=0.01, tol=1e-05, score=0.0\n",
      "disgust: C=1.0, tol=1e-05, score=0.0\n",
      "anger: C=0.1, tol=0.0001, score=0.139903381643\n",
      "fear: C=1.0, tol=1e-05, score=0.394285714286\n",
      "sadness: C=0.1, tol=1e-05, score=0.0\n",
      "surprise: C=1.0, tol=1e-05, score=0.293333333333\n",
      "joy: C=0.1, tol=1e-05, score=0.0\n",
      "anger: C=1.0, tol=0.0001, score=0.0666666666667\n",
      "disgust: C=0.001, tol=0.0001, score=0.0\n",
      "fear: C=0.001, tol=0.0001, score=0.181570048309\n",
      "sadness: C=1.0, tol=1e-05, score=0.426153846154\n",
      "anger: C=0.001, tol=1e-06, score=0.181570048309\n",
      "surprise: C=0.001, tol=0.0001, score=0.32\n",
      "joy: C=1.0, tol=1e-05, score=0.564680756396\n",
      "disgust: C=0.01, tol=0.0001, score=0.0\n",
      "anger: C=0.01, tol=1e-06, score=0.0\n",
      "fear: C=0.01, tol=0.0001, score=0.0\n",
      "surprise: C=0.01, tol=0.0001, score=0.0\n",
      "sadness: C=0.001, tol=0.0001, score=0.125490196078\n",
      "joy: C=0.001, tol=0.0001, score=0.0\n",
      "disgust: C=0.1, tol=0.0001, score=0.146666666667\n",
      "anger: C=0.1, tol=1e-06, score=0.139903381643\n",
      "fear: C=0.1, tol=0.0001, score=0.302051499717\n",
      "surprise: C=0.1, tol=0.0001, score=0.154141414141\n",
      "disgust: C=1.0, tol=0.0001, score=0.0\n",
      "sadness: C=0.01, tol=0.0001, score=0.0\n",
      "joy: C=0.01, tol=0.0001, score=0.0\n",
      "anger: C=1.0, tol=1e-06, score=0.0\n",
      "fear: C=1.0, tol=0.0001, score=0.394285714286\n",
      "surprise: C=1.0, tol=0.0001, score=0.293333333333\n",
      "disgust: C=0.001, tol=1e-06, score=0.0\n",
      "sadness: C=0.1, tol=0.0001, score=0.0\n",
      "joy: C=0.1, tol=0.0001, score=0.0\n",
      "anger: C=0.001, tol=1e-05, score=0.181570048309\n",
      "fear: C=0.001, tol=1e-06, score=0.181570048309\n",
      "surprise: C=0.001, tol=1e-06, score=0.32\n",
      "sadness: C=1.0, tol=0.0001, score=0.426153846154\n",
      "disgust: C=0.01, tol=1e-06, score=0.0\n",
      "anger: C=0.01, tol=1e-05, score=0.0\n",
      "joy: C=1.0, tol=0.0001, score=0.564680756396\n",
      "fear: C=0.01, tol=1e-06, score=0.0\n",
      "surprise: C=0.01, tol=1e-06, score=0.0\n",
      "anger: C=0.1, tol=1e-05, score=0.139903381643\n",
      "disgust: C=0.1, tol=1e-06, score=0.0\n",
      "sadness: C=0.001, tol=1e-06, score=0.125490196078\n",
      "joy: C=0.001, tol=1e-06, score=0.0\n",
      "fear: C=0.1, tol=1e-06, score=0.0703381642512\n",
      "anger: C=1.0, tol=1e-05, score=0.0\n",
      "surprise: C=0.1, tol=1e-06, score=0.0\n",
      "disgust: C=1.0, tol=1e-06, score=0.0\n",
      "sadness: C=0.01, tol=1e-06, score=0.0\n",
      "joy: C=0.01, tol=1e-06, score=0.0\n",
      "fear: C=1.0, tol=1e-06, score=0.146666666667\n",
      "anger: C=0.001, tol=0.0001, score=0.181570048309\n",
      "surprise: C=1.0, tol=1e-06, score=0.0\n",
      "disgust: C=0.001, tol=1e-05, score=0.0\n",
      "sadness: C=0.1, tol=1e-06, score=0.0\n",
      "joy: C=0.1, tol=1e-06, score=0.0\n",
      "fear: C=0.001, tol=1e-05, score=0.181570048309\n",
      "anger: C=0.01, tol=0.0001, score=0.0\n",
      "surprise: C=0.001, tol=1e-05, score=0.32\n",
      "disgust: C=0.01, tol=1e-05, score=0.0\n",
      "joy: C=1.0, tol=1e-06, score=0.0470588235294\n",
      "sadness: C=1.0, tol=1e-06, score=0.0\n",
      "anger: C=0.1, tol=0.0001, score=0.139903381643\n",
      "fear: C=0.01, tol=1e-05, score=0.0\n",
      "surprise: C=0.01, tol=1e-05, score=0.0\n",
      "disgust: C=0.1, tol=1e-05, score=0.0\n",
      "anger: C=1.0, tol=0.0001, score=0.0\n",
      "joy: C=0.001, tol=1e-05, score=0.0\n",
      "sadness: C=0.001, tol=1e-05, score=0.125490196078\n",
      "fear: C=0.1, tol=1e-05, score=0.0703381642512\n",
      "surprise: C=0.1, tol=1e-05, score=0.0\n",
      "anger: C=0.001, tol=1e-06, score=0.181570048309\n",
      "disgust: C=1.0, tol=1e-05, score=0.0\n",
      "joy: C=0.01, tol=1e-05, score=0.0\n",
      "fear: C=1.0, tol=1e-05, score=0.146666666667\n",
      "sadness: C=0.01, tol=1e-05, score=0.0\n",
      "anger: C=0.01, tol=1e-06, score=0.0\n",
      "surprise: C=1.0, tol=1e-05, score=0.0\n",
      "disgust: C=0.001, tol=0.0001, score=0.0\n",
      "fear: C=0.001, tol=0.0001, score=0.181570048309\n",
      "joy: C=0.1, tol=1e-05, score=0.0\n",
      "sadness: C=0.1, tol=1e-05, score=0.0\n",
      "anger: C=0.1, tol=1e-06, score=0.139903381643\n",
      "surprise: C=0.001, tol=0.0001, score=0.32\n",
      "disgust: C=0.01, tol=0.0001, score=0.0\n",
      "fear: C=0.01, tol=0.0001, score=0.0\n",
      "joy: C=1.0, tol=1e-05, score=0.0470588235294\n",
      "anger: C=1.0, tol=1e-06, score=0.0\n",
      "sadness: C=1.0, tol=1e-05, score=0.0\n",
      "surprise: C=0.01, tol=0.0001, score=0.0\n",
      "disgust: C=0.1, tol=0.0001, score=0.0\n",
      "anger: C=0.001, tol=1e-05, score=0.181570048309\n",
      "fear: C=0.1, tol=0.0001, score=0.0703381642512\n",
      "joy: C=0.001, tol=0.0001, score=0.0\n",
      "sadness: C=0.001, tol=0.0001, score=0.125490196078\n",
      "surprise: C=0.1, tol=0.0001, score=0.0\n",
      "disgust: C=1.0, tol=0.0001, score=0.0\n",
      "anger: C=0.01, tol=1e-05, score=0.0\n",
      "fear: C=1.0, tol=0.0001, score=0.146666666667\n",
      "joy: C=0.01, tol=0.0001, score=0.0\n",
      "sadness: C=0.01, tol=0.0001, score=0.0\n",
      "surprise: C=1.0, tol=0.0001, score=0.0\n",
      "anger: C=0.1, tol=1e-05, score=0.139903381643\n",
      "disgust: C=0.001, tol=1e-06, score=0.0\n",
      "fear: C=0.001, tol=1e-06, score=0.181570048309\n",
      "joy: C=0.1, tol=0.0001, score=0.0\n",
      "anger: C=1.0, tol=1e-05, score=0.0\n",
      "sadness: C=0.1, tol=0.0001, score=0.0\n",
      "surprise: C=0.001, tol=1e-06, score=0.32\n",
      "disgust: C=0.01, tol=1e-06, score=0.0\n",
      "fear: C=0.01, tol=1e-06, score=0.0\n",
      "joy: C=1.0, tol=0.0001, score=0.0470588235294\n",
      "anger: C=0.001, tol=0.0001, score=0.181570048309\n",
      "sadness: C=1.0, tol=0.0001, score=0.0\n",
      "surprise: C=0.01, tol=1e-06, score=0.0\n",
      "disgust: C=0.1, tol=1e-06, score=0.0\n",
      "fear: C=0.1, tol=1e-06, score=0.14148440931\n",
      "anger: C=0.01, tol=0.0001, score=0.0\n",
      "joy: C=0.001, tol=1e-06, score=0.0\n",
      "surprise: C=0.1, tol=1e-06, score=0.0\n",
      "sadness: C=0.001, tol=1e-06, score=0.125490196078\n",
      "disgust: C=1.0, tol=1e-06, score=0.0\n",
      "anger: C=0.1, tol=0.0001, score=0.139903381643\n",
      "fear: C=1.0, tol=1e-06, score=0.146666666667\n",
      "joy: C=0.01, tol=1e-06, score=0.0\n",
      "surprise: C=1.0, tol=1e-06, score=0.0\n",
      "sadness: C=0.01, tol=1e-06, score=0.0\n",
      "disgust: C=0.001, tol=1e-05, score=0.0\n",
      "anger: C=1.0, tol=0.0001, score=0.0\n",
      "['anger', 0.18157004830917872, 'SVC', 0.001, 0.1, 0.001, 1e-06, 4, 200]\n",
      "fear: C=0.001, tol=1e-05, score=0.181570048309\n",
      "joy: C=0.1, tol=1e-06, score=0.0\n",
      "surprise: C=0.001, tol=1e-05, score=0.32\n",
      "disgust: C=0.01, tol=1e-05, score=0.0\n",
      "sadness: C=0.1, tol=1e-06, score=0.0\n",
      "fear: C=0.01, tol=1e-05, score=0.0\n",
      "joy: C=1.0, tol=1e-06, score=0.0470588235294\n",
      "surprise: C=0.01, tol=1e-05, score=0.0\n",
      "disgust: C=0.1, tol=1e-05, score=0.0\n",
      "sadness: C=1.0, tol=1e-06, score=0.0\n",
      "fear: C=0.1, tol=1e-05, score=0.14148440931\n",
      "joy: C=0.001, tol=1e-05, score=0.0\n",
      "surprise: C=0.1, tol=1e-05, score=0.0\n",
      "disgust: C=1.0, tol=1e-05, score=0.0\n",
      "fear: C=1.0, tol=1e-05, score=0.146666666667\n",
      "sadness: C=0.001, tol=1e-05, score=0.125490196078\n",
      "joy: C=0.01, tol=1e-05, score=0.0\n",
      "surprise: C=1.0, tol=1e-05, score=0.0\n",
      "disgust: C=0.001, tol=0.0001, score=0.0\n",
      "fear: C=0.001, tol=0.0001, score=0.181570048309\n",
      "sadness: C=0.01, tol=1e-05, score=0.0\n",
      "joy: C=0.1, tol=1e-05, score=0.0\n",
      "surprise: C=0.001, tol=0.0001, score=0.32\n",
      "disgust: C=0.01, tol=0.0001, score=0.0\n",
      "fear: C=0.01, tol=0.0001, score=0.0\n",
      "sadness: C=0.1, tol=1e-05, score=0.0\n",
      "joy: C=1.0, tol=1e-05, score=0.0470588235294\n",
      "surprise: C=0.01, tol=0.0001, score=0.0\n",
      "fear: C=0.1, tol=0.0001, score=0.14148440931\n",
      "disgust: C=0.1, tol=0.0001, score=0.0\n",
      "sadness: C=1.0, tol=1e-05, score=0.0\n",
      "joy: C=0.001, tol=0.0001, score=0.0\n",
      "surprise: C=0.1, tol=0.0001, score=0.0\n",
      "fear: C=1.0, tol=0.0001, score=0.146666666667\n",
      "['fear', 0.44761904761904764, 'SVC', 1.0, 0.001, 0.001, 1e-06, 4, 200]\n",
      "disgust: C=1.0, tol=0.0001, score=0.0\n",
      "['disgust', 0.14666666666666667, 'SVC', 0.1, 0.01, 0.001, 1e-06, 4, 200]\n",
      "sadness: C=0.001, tol=0.0001, score=0.125490196078\n",
      "joy: C=0.01, tol=0.0001, score=0.0\n",
      "surprise: C=1.0, tol=0.0001, score=0.0\n",
      "['surprise', 0.32000000000000001, 'SVC', 0.001, 0.001, 0.001, 1e-06, 4, 200]\n",
      "sadness: C=0.01, tol=0.0001, score=0.0\n",
      "joy: C=0.1, tol=0.0001, score=0.0\n",
      "sadness: C=0.1, tol=0.0001, score=0.0\n",
      "joy: C=1.0, tol=0.0001, score=0.0470588235294\n",
      "['joy', 0.56468075639599558, 'SVC', 1.0, 0.01, 0.001, 1e-06, 4, 200]\n",
      "sadness: C=1.0, tol=0.0001, score=0.0\n",
      "['sadness', 0.42615384615384605, 'SVC', 1.0, 0.01, 0.001, 1e-06, 4, 200]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "ESTIMATOR = 'LinearSVC'\n",
    "cv_folds = 5\n",
    "\n",
    "def foo(EMOTION=0):   \n",
    "    rs = np.random.randint(low = 0, high = len(X),size = int(len(X)/100))    \n",
    "    # X, y2 = X[rs], y2[rs]\n",
    "    \n",
    "    y2 = []\n",
    "    for ly in y:   \n",
    "        y2.append(int(ly[EMOTION]))        \n",
    "    y2 = np.asarray(y2)\n",
    "    \n",
    "    if(EMOTION == 5):\n",
    "        foo2(X_3[rs], y2[rs], EMOTION=EMOTION)\n",
    "    elif(EMOTION == 3):\n",
    "        foo2(X_2[rs], y2[rs], EMOTION=EMOTION)\n",
    "    else:\n",
    "        foo2(X[rs], y2[rs], EMOTION=EMOTION)\n",
    "\n",
    "def foo2(X,y,EMOTION=0): \n",
    "           \n",
    "\n",
    "    list_acc = []    \n",
    "    list_val = []\n",
    "        \n",
    "    if(ESTIMATOR == 'LinearSVC'):                             \n",
    "        epsilon = 0.001\n",
    "        gamma=1.0\n",
    "        for tol in [1e-6,1e-5,1e-4]:\n",
    "            for C in [0.01,0.1,1.0]:\n",
    "                cvs = cross_val_score(estimator = LinearSVC(C=C, class_weight='balanced', penalty='l1', dual=False, tol=tol), X=X, y=y, cv=cv_folds, n_jobs=cv_folds, scoring='f1') \n",
    "                meanScore = np.mean(np.asarray(cvs))\n",
    "                list_val.append([emoNames[EMOTION],meanScore,ESTIMATOR, C, gamma,epsilon,tol,NGRAM_VALUE,EMBEDDINGS_DIM])\n",
    "                list_acc.append(meanScore)\n",
    "                print(emoNames[EMOTION]+': C='+str(C)+', tol='+str(tol)+', score='+str(meanScore))\n",
    "        best = np.argmax(list_acc)\n",
    "        print(list_val[best])\n",
    "        \n",
    "    elif(ESTIMATOR == 'SVC'):                          \n",
    "        epsilon = 0.001\n",
    "        for gamma in [0.001,0.01,0.1,1.0]:\n",
    "            for tol in [1e-6,1e-5,1e-4]:\n",
    "                for C in [0.001,0.01,0.1,1.0]:\n",
    "                    cvs = cross_val_score(estimator = SVC(C=C, class_weight='balanced', tol=tol, gamma=gamma), X=X, y=y, cv=cv_folds, n_jobs=cv_folds, scoring='f1') \n",
    "                    meanScore = np.mean(np.asarray(cvs))\n",
    "                    list_val.append([emoNames[EMOTION],meanScore,ESTIMATOR, C, gamma,epsilon,tol,NGRAM_VALUE,EMBEDDINGS_DIM])\n",
    "                    list_acc.append(meanScore)\n",
    "                    print(emoNames[EMOTION]+': C='+str(C)+', tol='+str(tol)+', score='+str(meanScore))\n",
    "        best = np.argmax(list_acc)\n",
    "        print(list_val[best])\n",
    "        \n",
    "    return list_val[best]\n",
    "            \n",
    "\n",
    "# print('emotion, f1_score, estimator, C, gamma, epsilon, tol, ngrams, EMBEDDINGS_DIM')  \n",
    "p = Pool(processes = 6)\n",
    "results = p.map(foo, [i for i in  range(len(emoNames))])\n",
    "# foo(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "['sadness', 0.42615384615384605, 'SVC', 1.0, 0.01, 0.001, 1e-06, 4, 200]\n",
    "['disgust', 0.14666666666666667, 'SVC', 0.1, 0.01, 0.001, 1e-06, 4, 200]\n",
    "['surprise', 0.32000000000000001, 'SVC', 0.001, 0.001, 0.001, 1e-06, 4, 200]\n",
    "['anger', 0.18157004830917872, 'SVC', 0.001, 0.1, 0.001, 1e-06, 4, 200]\n",
    "['fear', 0.44761904761904764, 'SVC', 1.0, 0.001, 0.001, 1e-06, 4, 200]\n",
    "['joy', 0.56468075639599558, 'SVC', 1.0, 0.01, 0.001, 1e-06, 4, 200]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SAVE CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_params_linear = {\n",
    "        'sadness': {'C': 0.1, 'tol':1.00E-04},\n",
    "        'disgust': {'C': 0.1, 'tol':1.00E-04},\n",
    "        'surprise': {'C': 0.1, 'tol':1.00E-06},\n",
    "        'anger': {'C': 1.0, 'tol':1.00E-05},\n",
    "        'fear': {'C': 1.0, 'tol':1.00E-04},\n",
    "        'joy': {'C': 0.1, 'tol':1.00E-04}\n",
    "    }\n",
    "\n",
    "train_params_rbf = {\n",
    "        'sadness': {'C': 0.1, 'gamma': 0.01, 'tol':1.00E-05},\n",
    "         'disgust': {'C': 0.1, 'gamma': 0.01, 'tol':1.00E-04},\n",
    "         'surprise': {'C': 0.1, 'gamma': 0.001, 'tol':1.00E-06},\n",
    "         'anger': {'C': 1.0, 'gamma': 0.1, 'tol':1.00E-05},\n",
    "         'fear': {'C': 1.0, 'gamma': 0.001, 'tol':1.00E-05},\n",
    "         'joy': {'C': 0.1, 'gamma': 0.01, 'tol':1.00E-04}\n",
    "    }\n",
    "\n",
    "train_params = {'LinearSVC':train_params_linear, 'SVC':train_params_rbf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save the Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "# from collections import Counter\n",
    "\n",
    "SEP = '/'\n",
    "EXTENSION = '.dump'\n",
    "ESTIMATOR = 'SVC'\n",
    "\n",
    "def ifExists(filename):\n",
    "    dir = os.path.dirname(filename)\n",
    "    try:\n",
    "        os.stat(dir)\n",
    "    except:\n",
    "        os.mkdir(dir) \n",
    "\n",
    "def trainModelFor(X, y, EMOTION=0):\n",
    "    \n",
    "    y2 = []\n",
    "    for ly in y:  \n",
    "        y2.append(int(ly[EMOTION]))        \n",
    "    y2 = np.asarray(y2)\n",
    "    \n",
    "#     rs = np.random.randint(low = 0, high = len(X),size = int(len(X)/100))    \n",
    "#     X, y2 = X[rs], y2[rs]\n",
    "    \n",
    "    \n",
    "    C = train_params[ESTIMATOR][ emoNames[EMOTION] ]['C'] \n",
    "    tol = train_params[ESTIMATOR][ emoNames[EMOTION] ]['tol']    \n",
    "        \n",
    "    class_weight = 'balanced'     \n",
    "\n",
    "   \n",
    "    if(ESTIMATOR == 'LinearSVC'):\n",
    "        svcTrained = LinearSVC(C=C, class_weight='balanced', penalty='l1', dual=False, tol=tol)\n",
    "        svcTrained.fit(X, y2)\n",
    "    elif(ESTIMATOR == 'SVC'):\n",
    "        gamma = train_params[ESTIMATOR][ emoNames[EMOTION] ]['gamma'] \n",
    "        svcTrained = SVC(C=C, gamma=gamma, class_weight='balanced', tol=tol, probability=True)\n",
    "        svcTrained.fit(X, y2)\n",
    "        \n",
    "    return(svcTrained)\n",
    "\n",
    "def checkFolder(filename):\n",
    "    dir = os.path.dirname(filename)\n",
    "    try:\n",
    "        os.stat(dir)\n",
    "    except:\n",
    "        os.mkdir(dir) \n",
    "\n",
    "def saveModelFor(model, EMOTION=0):\n",
    "    path = '/home/vlaand/IpythonNotebooks/05_emotion_hashtags_nuig/hashTagClassification/classifiers'\n",
    "    path = path +SEP+ESTIMATOR\n",
    "    checkFolder(path)\n",
    "    filename = path + SEP +str(emoNames[EMOTION]) + EXTENSION\n",
    "    checkFolder(filename)\n",
    "    _ = joblib.dump(model, filename, compress=9)\n",
    "\n",
    "    print('model ' + filename + ' saved')\n",
    "    \n",
    "def trainAndSave(emotion):\n",
    "#     if(emotion == 5):\n",
    "#         saveModelFor( EMOTION=emotion, model=trainModelFor(X, EMOTION=emotion) )\n",
    "#     elif(emotion == 3):\n",
    "#         saveModelFor( EMOTION=emotion, model=trainModelFor(X, EMOTION=emotion) )\n",
    "#     else:\n",
    "        saveModelFor( EMOTION=emotion, model=trainModelFor(X, y, EMOTION=emotion) )\n",
    "\n",
    "with Pool(processes = 6) as p: \n",
    "    p.map(trainAndSave, [i for i in range(len(emoNames))])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
